Coursera Data Science Specialisation Capstone Project
========================================================

The Capstone Project for the [Coursera Data Science Specialisation] (https://www.coursera.org/specializations/jhu-data-science) from John Hopkins University requires the development of a web application to predict the next word of a sentence.

This presentation will describe the application, its use and the way it predicts the next word.


Objective
========================================================

The web application takes the entered phrase and predicts the next word.

This application could be applied to predictive texting applications.  It is a simple and reasonably quick implementation to demonstrate the capabilities.

Through testing, a reasonable tradeoff between accuracy and performance was found.  However, with additional data and computing power the accuracy and performance could be improved further.


Instructions
========================================================

To start the application, open the Shiny application link [here](https://phickman.shinyapps.io/PredictNextWord/).

Once the application has started, enter a phrase into the Input text box on the left and press the Enter key or click the button under the Input box.

The input string will be passed to the prediction algorithm for processing against the ngram datasets.

After a second or two the algorithm will display the next predicted word on the right.

If the application times out, refresh the page to start again.


Data
========================================================

The data is sourced from English language Tweets, Blogs and News articles available [here](https://d396qusza40orc.cloudfront.net/dsscapstone/dataset/Coursera-SwiftKey.zip).

Due to the size of the dataset and computing power available, a random 1% of the dataset was used for predictions.

Before processing, the data was cleaned by removing punctuation and other unrequired characters and ngrams generated listing the most frequent first.


Algorithm
========================================================

The application implements the Stupid Backoff algorithm to predict the next word:

1. Clean the input sentence
2. Select at most the last 3 words of the sentence (this is because the prediction model uses quad-grams at most)
3. Depending on the number of words provided, get the quad, tri or bi -gram frequency dataset
4. Search for a match in the ngram dataset
5. If a match is found, return the next word (the dataset is ordered from highest to lowest frequency)
6. If no match is found, use next ngram dataset (i.e. if using quadgram, then move to trigram dataset and so on)
7. Repeat until a match is found, if no match is found then return the most common unigram word
